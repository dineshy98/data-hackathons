{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Apr  4 20:09:32 2021\n",
    "\n",
    "@author: dineshy86\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,GridSearchCV,GroupKFold,train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "test = pd.read_csv('Test Data.csv')\n",
    "test['risk_flag'] = -1\n",
    "sample = pd.read_csv('Sample Prediction Dataset.csv')\n",
    "train = pd.read_csv('Training Data.csv')\n",
    "\n",
    "\n",
    "train.columns\n",
    "train['risk_flag'].value_counts()\n",
    "data = pd.concat([train,test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#feature engineering\n",
    "data.isnull().sum()\n",
    "\n",
    "\n",
    "#1.feature_intraction\n",
    "\n",
    "cat_cols = [ 'married', 'house_ownership',\n",
    "       'car_ownership', 'profession', 'city', 'state']\n",
    "\n",
    "\n",
    "for lisst in [\n",
    "        ['married','house_ownership'],\n",
    "        ['house_ownership','car_ownership'],\n",
    "        ['house_ownership','car_ownership','profession'],\n",
    "        ['profession','city']\n",
    "        ]:\n",
    "\n",
    "    \n",
    "    if len(lisst) == 2:\n",
    "       data['_'.join(lisst)] = data[lisst[0]] +'_'+ data[lisst[1]]\n",
    "    \n",
    "    elif len(lisst) == 3:\n",
    "        data['_'.join(lisst)] = data[lisst[0]] +  '_' + data[lisst[1]] + '_' + data[lisst[2]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data.columns\n",
    "\n",
    "cat_cols = [ 'married', 'house_ownership',\n",
    "       'car_ownership', 'profession', 'city', 'state',\n",
    "       'married_house_ownership',\n",
    "       'house_ownership_car_ownership',\n",
    "       'house_ownership_car_ownership_profession', 'profession_city']\n",
    "\n",
    "\n",
    "drop_cols = ['id' ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_auc_score,f1_score,accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "data.drop(columns = drop_cols,inplace = True)\n",
    "\n",
    "\n",
    "import category_encoders as ce\n",
    "encd = ce.cat_boost.CatBoostEncoder(cols=cat_cols,return_df=True)\n",
    "data1 = encd.fit_transform(data,data['risk_flag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sec_lev_data = pd.concat([data.loc[data['risk_flag'] == 0].sample(10000),data.loc[data['risk_flag'] == 1].sample(10000)])\n",
    "\n",
    "\n",
    "test_df = data.loc[data['risk_flag'] == -1].drop(columns = ['risk_flag'])\n",
    "data.drop(data.loc[data['risk_flag'] == -1].index,inplace = True)\n",
    "\n",
    "\n",
    "data.drop(sec_lev_data.index,inplace = True)\n",
    "data.reset_index(drop = True,inplace = True)\n",
    "\n",
    "\n",
    "data0_cat = data[data['risk_flag'] == 0].reset_index(drop = True)\n",
    "data1_cat = data[data['risk_flag'] == 1].reset_index(drop = True)\n",
    "\n",
    "\n",
    "#cat_enabled_models\n",
    "\n",
    "data['risk_flag'].value_counts()\n",
    "\n",
    "def make_datasets(df):\n",
    "    \n",
    "    test_df = df.loc[df['risk_flag'] == -1].drop(columns = ['risk_flag'])\n",
    "    df0 = df[df['risk_flag'] == 0].reset_index(drop = True)\n",
    "    df1 = df[df['risk_flag'] == 1].reset_index(drop = True)\n",
    "    \n",
    "    return test_df,df0,df1\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    globals()['data0_cat%s' % i] = data0_cat[20996*i:20996*(i+1)]\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    globals()['train_df1_cat%s' % i] = pd.concat([globals()['data0_cat%s' % i],data1_cat])\n",
    "    globals()['train_df1_cat%s' % i] = globals()['train_df1_cat%s' % i].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for i in range(4):\n",
    " #   globals()['train_df1_cat%s' % i].drop(columns = drop_cols,inplace = True)\n",
    "    \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_auc_score,confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    globals()['X_tr_cat%s' % i],globals()['X_tst_cat%s' % i],globals()['y_tr_cat%s' % i],globals()['y_tst_cat%s' % i] = train_test_split(globals()['train_df1_cat%s' % i].drop(columns = ['risk_flag']),globals()['train_df1_cat%s' % i]['risk_flag'],stratify = globals()['train_df1_cat%s' % i]['risk_flag'])\n",
    "\n",
    "\n",
    "\n",
    "score = {}\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "for i in range(4):\n",
    "    \n",
    "    globals()['catboost%s' % i]=CatBoostClassifier(iterations = 2000,eval_metric = 'F1')\n",
    "    globals()['catboost%s' % i].fit(globals()['X_tr_cat%s' % i], globals()['y_tr_cat%s' % i],cat_features=cat_cols,eval_set=(globals()['X_tst_cat%s' % i], globals()['y_tst_cat%s' % i]))\n",
    "    score['catboost{}'.format(i)] = roc_auc_score(globals()['y_tst_cat%s' % i],globals()['catboost%s' % i].predict(globals()['X_tst_cat%s' % i]))\n",
    "\n",
    "############### LEVEL 2 ###############################\n",
    "\n",
    "\n",
    "\n",
    "#creating level2 training set\n",
    "\n",
    "preds = pd.DataFrame()\n",
    "for i in range(4):\n",
    "    \n",
    "    preds['catboost{}'.format(i)] = globals()['catboost%s' % i].predict_proba(sec_lev_data.drop(columns = ['risk_flag']))[:,1]\n",
    "\n",
    "\n",
    "\n",
    "sec_lev_data.reset_index(inplace = True,drop = True)\n",
    "preds['risk_flag'] = sec_lev_data['risk_flag']\n",
    "preds = preds.sample(frac= 1)\n",
    "\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost5 = CatBoostClassifier(iterations = 2000,eval_metric = 'F1')\n",
    "\n",
    "X_tr_lev2,X_tst_lev2,y_tr_lev2,y_tst_lev2 = train_test_split(preds.drop(columns = ['risk_flag']),preds['risk_flag'],stratify = preds['risk_flag'])\n",
    "\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "catboost5=CatBoostClassifier(iterations = 2000,eval_metric = 'F1')\n",
    "catboost5.fit(X_tr_lev2, y_tr_lev2,eval_set=(X_tst_lev2, y_tst_lev2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#predicting test\n",
    "\n",
    "\n",
    "test_preds = pd.DataFrame()\n",
    "for i in range(4):\n",
    "    \n",
    "    test_preds['catboost{}'.format(i)] = globals()['catboost%s' % i].predict_proba(test_df)[:,1]\n",
    "\n",
    "sample['risk_flag'] =  catboost5.predict(test_preds)\n",
    "sample.to_csv('catboost_ensembled_4stacking.csv',index = False)\n",
    "\n",
    "\n",
    "counts = pd.DataFrame()\n",
    "counts['1s'] = preds.sum(axis = 1)\n",
    "counts['0s'] = 4 - counts['1s']\n",
    "\n",
    "\n",
    "sample['risk_flag'] = counts['1s'].apply(lambda x : 1 if x > 3 else 0)\n",
    "\n",
    "sample['risk_flag'].value_counts()\n",
    "\n",
    "\n",
    "sample2 = pd.read_csv('catboost_ensembled_frop_duplicated_4_3_1s.csv')\n",
    "\n",
    "\n",
    "\n",
    "confusion_matrix(sample['risk_flag'],sample2['risk_flag'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample['risk_flag'] = catboost0.predict(test_df.drop(columns = ['risk_flag']))\n",
    "sample.to_csv('catboost.csv',index = False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_df = data1.loc[data1['risk_flag'] != -1]\n",
    "test_df = data1.loc[data1['risk_flag'] == -1]\n",
    "test_df.drop(columns = ['risk_flag'],inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_tr,X_tst,y_tr,y_tst = train_test_split(train_df.drop(columns = ['risk_flag']),train_df['risk_flag'],stratify = train_df['risk_flag'])\n",
    "\n",
    "weighted_clf = RandomForestClassifier(max_depth=3 ,random_state=0,class_weight={0:0.2,1:0.8}).fit(X_tr, y_tr)\n",
    "roc_auc_score(y_tst,weighted_clf.predict(X_tst))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# we can add class_weight='balanced' to add panalize mistake\n",
    "svc_model = SVC(class_weight='balanced')\n",
    "\n",
    "svc_model.fit(X_tr, y_tr)\n",
    "\n",
    "svc_predict = svc_model.predict(X_tst)# check performance\n",
    "print('ROCAUC score:',roc_auc_score(y_tst, svc_predict))\n",
    "print('Accuracy score:',accuracy_score(y_tst, svc_predict))\n",
    "print('F1 score:',f1_score(y_tst, svc_predict))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
